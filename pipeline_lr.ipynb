{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor  # Example model\n",
    "\n",
    "from sklearn.linear_model import Lasso,ElasticNet\n",
    "from sklearn.model_selection import GridSearchCV,cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error,make_scorer\n",
    "import numpy as np\n",
    "\n",
    "def mae_exp(y_true_log, y_pred_log):\n",
    "    y_true = np.exp(y_true_log)\n",
    "    y_pred = np.exp(y_pred_log)\n",
    "    return mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "# Create a scorer from the custom scoring function\n",
    "mae_exp_scorer = make_scorer(mae_exp, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TargetCorrelation(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, threshold=0.01):\n",
    "        self.threshold = threshold\n",
    "        self.correlated_features = set()\n",
    "        self.feature_names_ =None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.feature_names_ = None\n",
    "        self.correlated_features.clear()\n",
    "        # Calculate correlation matrix\n",
    "        correlation_matrix = pd.DataFrame(X.join(y)).corr()\n",
    "        # Print the correlation between each feature and the target variable\n",
    "        # print(\"Correlation with Target:\")\n",
    "        for feature in X.columns[:-1]:  # Exclude the last column which is the target itself\n",
    "            correlation_with_target = abs(correlation_matrix.at[feature, 'age'])\n",
    "            # print(f\"{feature}: {correlation_with_target:.4f}\")\n",
    "            if correlation_with_target < self.threshold:\n",
    "                self.correlated_features.add(feature)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        existing_correlated_features = self.correlated_features.intersection(set(X.columns))\n",
    "        # print(\"TTTTTTTTTTTTTTTTTTTTTTT:\",existing_correlated_features)\n",
    "        X = X.drop(labels=existing_correlated_features, axis=1)\n",
    "        # self.correlated_features.clear()\n",
    "        self.feature_names_ = X.columns.tolist()\n",
    "        return X\n",
    "    \n",
    "    def get_feature_names_out(self):\n",
    "        return  self.feature_names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CorrelationThreshold(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, threshold=0.8):\n",
    "        self.threshold = threshold\n",
    "        self.correlated_features = set()\n",
    "        self.feature_names_ =None\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        self.feature_names_ = None\n",
    "        self.correlated_features.clear()\n",
    "        \n",
    "        # Calculate the correlation matrix\n",
    "        corr_matrix = pd.DataFrame(data=X).corr()\n",
    "        for i in range(len(corr_matrix.columns)):\n",
    "            for j in range(i):\n",
    "                if abs(corr_matrix.iloc[i, j]) > self.threshold:\n",
    "                    colname = corr_matrix.columns[i]\n",
    "                    self.correlated_features.add(colname)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        existing_correlated_features = self.correlated_features.intersection(set(X.columns))\n",
    "        X = X.drop(labels=existing_correlated_features, axis=1)\n",
    "        # self.correlated_features.clear()\n",
    "        self.feature_names_ = X.columns.tolist()\n",
    "        return X\n",
    "    \n",
    "    def get_feature_names_out(self):\n",
    "        return  self.feature_names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFrameVarianceThreshold(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, threshold=0.0):\n",
    "        # Initialize the VarianceThreshold with the given threshold\n",
    "        self.threshold = threshold\n",
    "        self.selector = VarianceThreshold(self.threshold)\n",
    "        self.feature_names_ = None\n",
    "    def fit(self, X, y=None):\n",
    "        self.feature_names_ = None\n",
    "        # Fit the VarianceThreshold selector to the DataFrame\n",
    "        self.selector.fit(X)\n",
    "        self.feature_names_ = X.columns.tolist()\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Apply the selector to the DataFrame\n",
    "        transformed_array = self.selector.transform(X)\n",
    "        # Convert the output back to a DataFrame\n",
    "        # Get the support mask (boolean array) of the features selected\n",
    "        features = X.columns[self.selector.get_support()]\n",
    "        self.feature_names_ = features.tolist()\n",
    "        transformed_df = pd.DataFrame(transformed_array, index=X.index, columns=features)\n",
    "        return transformed_df\n",
    "    \n",
    "    def get_feature_names_out(self):\n",
    "        return self.feature_names_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFrameStandardScaler(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        # Initialize the StandardScaler\n",
    "        self.scaler = StandardScaler()\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        # Fit the scaler to the data, ensuring X is a DataFrame\n",
    "        self.scaler.fit(X)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Apply the scaler to the DataFrame\n",
    "        scaled_array = self.scaler.transform(X)\n",
    "        # Return a DataFrame, maintaining the same index and column labels\n",
    "        scaled_df = pd.DataFrame(scaled_array, index=X.index, columns=X.columns)\n",
    "        return scaled_df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV,LinearRegression,Ridge\n",
    "\n",
    "class LassoFeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, alphas=1, cv=5):\n",
    "        self.alphas = alphas\n",
    "        self.cv = cv\n",
    "        self.model = Lasso(alpha=alphas, random_state=42)\n",
    "        self.support_ = None\n",
    "        self.feature_names_ = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # reset\n",
    "        self.feature_names_ = None\n",
    "        self.support_ = None\n",
    "        # Fit the LassoCV model to the data\n",
    "        self.model.fit(X, y)\n",
    "        # Find the indices of the features with non-zero coefficients\n",
    "        self.support_ = self.model.coef_ != 0\n",
    "        self.feature_names_ = X.columns[self.support_].tolist()\n",
    "       \n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Return the DataFrame with only the selected features\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            return X.loc[:, self.support_]\n",
    "        else:\n",
    "            return X[:, self.support_]\n",
    "        \n",
    "    def get_feature_names_out(self):\n",
    "        return self.feature_names_  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('correlation_threshold', CorrelationThreshold(threshold=0.8)),  # Adjust threshold as needed\n",
    "    ('variance_threshold', DataFrameVarianceThreshold(threshold=0.0001)),  # Adjust threshold as needed\n",
    "    # ('target_correlation',TargetCorrelation()),\n",
    "    ('standard_scaler', DataFrameStandardScaler()),\n",
    "    ('model', LinearRegression())  # Example model\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'correlation_threshold__threshold' : [0.8,0.9,1],\n",
    "    'variance_threshold__threshold' : [0.0001,0.001],\n",
    "    # 'lasso_feature__alphas': np.logspace(-4, -0.5, 20),\n",
    "    # 'target_correlation__threshold' : [0.001,0.01,0.0001]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe = pd.read_csv(r'C:\\Users\\User\\OneDrive\\Desktop\\毕业论文2024\\Notebook\\Data\\before_shuffle\\transformed_merged_hemisphere.csv')\n",
    "# dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = ['original','transformed_original','merged_hemisphere','transformed_merged_hemisphere','grouped_merged']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Load your data\n",
    "dataframe = pd.read_csv(fr'C:\\Users\\User\\OneDrive\\Desktop\\毕业论文2024\\Notebook\\Data\\without_fake\\{filename[0]}.csv')\n",
    "   \n",
    "y = (dataframe['age'])\n",
    "X = dataframe.drop('age',axis = 1)\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "\n",
    "# %store -r lr_merged_selected\n",
    "# x_train = x_train[lr_merged_selected]\n",
    "# x_test = x_test[lr_merged_selected]    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features= dataframe.filter(regex = 'interaction').columns.tolist()\n",
    "\n",
    "dataframe = dataframe.drop(cat_features,axis = 1)\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# encoder = OneHotEncoder(sparse_output=False,drop='first')\n",
    "# x_train_encoded = encoder.fit_transform(x_train[cat_features])\n",
    "\n",
    "# encoded_df = pd.DataFrame(x_train_encoded,columns=encoder.get_feature_names_out())\n",
    "# encoded_df\n",
    "\n",
    "# x_train = x_train.reset_index(drop=True)\n",
    "# x_train = pd.concat([x_train,encoded_df],axis = 1).drop(cat_features,axis = 1)\n",
    "\n",
    "# x_test_encoded = encoder.transform(x_test[cat_features])\n",
    "# encoded_df = pd.DataFrame(x_test_encoded,columns = encoder.get_feature_names_out())\n",
    "\n",
    "# x_test = x_test.reset_index(drop=True)\n",
    "# x_test = pd.concat([x_test,encoded_df],axis = 1).drop(cat_features,axis = 1)\n",
    "# x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error,r2_score\n",
    "from  scipy.stats import pearsonr\n",
    "\n",
    "# pipeline.fit(x_train,y_train)\n",
    "# # Predict using the best model\n",
    "# y_pred = pipeline.predict(x_test)\n",
    "\n",
    "# cv_lr = cross_val_score(pipeline, x_train, y_train, cv=8, scoring='neg_mean_absolute_error')\n",
    "\n",
    "\n",
    "# # Evaluate the model\n",
    "# mae = mean_absolute_error(y_test, y_pred)\n",
    "# print(\"lienar regression : \",np.mean((-cv_lr)))\n",
    "\n",
    "# print(\"Test Mean absolute Error:\", mae)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(x_train,y_train)\n",
    "\n",
    "baseline_mae = -np.mean(cross_val_score(pipeline,x_train,y_train,scoring='neg_mean_absolute_error',cv=10))\n",
    "print(baseline_mae)\n",
    "y_pred = pipeline.predict(x_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"Test Mean absolute Error:\", mae)\n",
    "print('linear regression  r2: ',(r2_score(y_test,y_pred)))\n",
    "print('linear regression pearson: ',(pearsonr(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "currently determining the best hyperparam for variance and correlation evaluated using vanilla linear regresison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=10, scoring='neg_mean_absolute_error', verbose=1)\n",
    "\n",
    "# Fit the grid search\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Best parameters and score\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best cross-validation score (MSE):\", -grid_search.best_score_)\n",
    "\n",
    "# Predict using the best model\n",
    "y_pred = grid_search.predict(x_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"Test Mean absolute Error:\", mae)\n",
    "print('linear regression  r2: ',(r2_score(y_test,y_pred)))\n",
    "print('linear regression pearson: ',(pearsonr(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "mae = mean_absolute_error((y_test), (y_pred))\n",
    "print(\"Test Mean absolute Error:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the pipeline\n",
    "pipeline2 = Pipeline([\n",
    "    ('correlation_threshold', CorrelationThreshold(threshold=0.8)),  # Adjust threshold as needed\n",
    "    ('variance_threshold', DataFrameVarianceThreshold(threshold=0.0001)),  # Adjust threshold as needed\n",
    "    ('target_correlation',TargetCorrelation(threshold=0.001)),\n",
    "    ('standard_scaler', DataFrameStandardScaler()),\n",
    "    # ('lasso_feature' , LassoFeatureSelector(alphas = 0.0001)),\n",
    "    ('model', ElasticNet())  # Example model\n",
    "])\n",
    "\n",
    "\n",
    "# pipeline2.fit(x_train,y_train)\n",
    "# print(len(pipeline2.named_steps['correlation_threshold'].get_feature_names_out()))\n",
    "# print(len(pipeline2.named_steps['variance_threshold'].get_feature_names_out()))\n",
    "# print(len(pipeline2.named_steps['target_correlation'].get_feature_names_out()))\n",
    "\n",
    "# # print((pipeline2.named_steps['lasso_feature'].get_feature_names_out()))\n",
    "# print(pipeline2.named_steps['model'].n_features_in_)\n",
    "\n",
    "baseline_mae = -np.mean(cross_val_score(pipeline2,x_train,y_train,scoring=mae_exp_scorer,cv=10))\n",
    "print(baseline_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyternb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
